{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b709e558-cd35-4240-b99e-9c27be60a5f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 – Import the libraries and load the dataset\n",
    "First, we are going to import all the modules that we are going to need for training our model. The Keras library already contains some datasets and MNIST is one of them. So we can easily import the dataset and start working with it. The mnist.load_data() method returns us the training data, its labels and also the testing data and its labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f598cf17-884b-4312-a8af-c93bc13fcd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7a5496e-d738-4fdc-8868-f956309b74d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d23850a-797f-4901-b113-33e3bf22db21",
   "metadata": {},
   "source": [
    "# 2 – Preprocess the data\n",
    "The image data cannot be fed directly into the model so we need to perform some operations and process the data to make it ready for our neural network. The dimension of the training data is (60000,28,28). The CNN model will require one more dimension so we reshape the matrix to shape (60000,28,28,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da61a135-ca30-4ae5-aa5e-649c684b89e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=None)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=None)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f5b6cd-69ab-4db0-962b-f3f549a09dcb",
   "metadata": {},
   "source": [
    "# 3 – Create the model\n",
    "Now we will create our CNN model in Python data science project. A CNN model generally consists of convolutional and pooling layers. It works better for data that are represented as grid structures, this is the reason why CNN works well for image classification problems. The dropout layer is used to deactivate some of the neurons and while training, it reduces offer fitting of the model. We will then compile the model with the Adadelta optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6867e795-87ea-40e0-a74d-eb343db334d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 20\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),activation='relu',input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,optimizer=keras.optimizers.Adadelta(),metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b441305-4869-433f-8961-10b058ddffd3",
   "metadata": {},
   "source": [
    "# 4 – Train the model\n",
    "The model.fit() function of Keras will start the training of the model. It takes the training data, validation data, epochs, and batch size.\n",
    "\n",
    "It takes some time to train the model. After training, we save the weights and model definition in the ‘mnist.h5’ file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "152721ba-c983-40c7-942a-8f25dd87b9c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 61s 130ms/step - loss: 2.2569 - accuracy: 0.1767 - val_loss: 2.1884 - val_accuracy: 0.4269\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 69s 146ms/step - loss: 2.1485 - accuracy: 0.3440 - val_loss: 2.0532 - val_accuracy: 0.6287\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 59s 125ms/step - loss: 2.0086 - accuracy: 0.4739 - val_loss: 1.8711 - val_accuracy: 0.7074\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 1.8227 - accuracy: 0.5637 - val_loss: 1.6404 - val_accuracy: 0.7531\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 70s 149ms/step - loss: 1.6024 - accuracy: 0.6199 - val_loss: 1.3827 - val_accuracy: 0.7789\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 1.3816 - accuracy: 0.6584 - val_loss: 1.1412 - val_accuracy: 0.8011\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 1.1911 - accuracy: 0.6894 - val_loss: 0.9493 - val_accuracy: 0.8200\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 1.0483 - accuracy: 0.7124 - val_loss: 0.8093 - val_accuracy: 0.8313\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.9369 - accuracy: 0.7354 - val_loss: 0.7085 - val_accuracy: 0.8430\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 52s 110ms/step - loss: 0.8583 - accuracy: 0.7488 - val_loss: 0.6357 - val_accuracy: 0.8533\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 55s 117ms/step - loss: 0.7918 - accuracy: 0.7652 - val_loss: 0.5809 - val_accuracy: 0.8602\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.7445 - accuracy: 0.7781 - val_loss: 0.5389 - val_accuracy: 0.8671\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.7038 - accuracy: 0.7888 - val_loss: 0.5055 - val_accuracy: 0.8723\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 54s 116ms/step - loss: 0.6685 - accuracy: 0.7972 - val_loss: 0.4788 - val_accuracy: 0.8766\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.6400 - accuracy: 0.8054 - val_loss: 0.4565 - val_accuracy: 0.8806\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 56s 120ms/step - loss: 0.6192 - accuracy: 0.8118 - val_loss: 0.4376 - val_accuracy: 0.8854\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.5934 - accuracy: 0.8189 - val_loss: 0.4214 - val_accuracy: 0.8882\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 55s 118ms/step - loss: 0.5773 - accuracy: 0.8262 - val_loss: 0.4077 - val_accuracy: 0.8921\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 56s 119ms/step - loss: 0.5587 - accuracy: 0.8306 - val_loss: 0.3951 - val_accuracy: 0.8947\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 54s 115ms/step - loss: 0.5496 - accuracy: 0.8317 - val_loss: 0.3846 - val_accuracy: 0.8964\n",
      "The model has successfully trained\n",
      "Saving the model as mnist.h5\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(x_test, y_test))\n",
    "print(\"The model has successfully trained\")\n",
    "\n",
    "model.save('mnist.h5')\n",
    "print(\"Saving the model as mnist.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5448de9-8b35-4453-97f5-ba9ebadc5426",
   "metadata": {},
   "source": [
    "# 5 – Evaluate the model\n",
    "We have 10,000 images in our dataset which will be used to evaluate how good our model works. The testing data was not involved in the training of the data therefore, it is new data for our model. The MNIST dataset is well balanced so we can get around 99% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49ddb751-1a5e-484b-b144-83199714abeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.38459280133247375\n",
      "Test accuracy: 0.896399974822998\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f85c3af-fa62-4dc8-bf65-54de49736f1f",
   "metadata": {},
   "source": [
    "# 6 – Create GUI to predict digits\n",
    "Now for the GUI, we have created a new file in which we build an interactive window to draw digits on canvas and with a button, we can recognize the digit. The Tkinter library comes in the Python standard library. We have created a function predict_digit() that takes the image as input and then uses the trained model to predict the digit.\n",
    "\n",
    "Then we create the App class which is responsible for building the GUI for our app. We create a canvas where we can draw by capturing the mouse event and with a button, we trigger the predict_digit() function and display the results.\n",
    "\n",
    "Here’s the full code for our gui_digit_recognizer.py file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b58e1c14-f3c8-4fb4-acd7-ff4bc6ae2bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 6s 6s/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from tkinter import *\n",
    "import tkinter as tk\n",
    "import win32gui\n",
    "from PIL import ImageGrab, ImageOps\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('mnist.h5')\n",
    "\n",
    "def predict_digit(img):\n",
    "    #resize image to 28x28 pixels\n",
    "    img = img.resize((28,28))\n",
    "    #convert rgb to grayscale\n",
    "    img = img.convert('L')\n",
    "    img = ImageOps.invert(img)\n",
    "    img = np.array(img)\n",
    "    #reshaping to support our model input and normalizing\n",
    "    img = img.reshape(1,28,28,1)\n",
    "    img = img/255.0\n",
    "    #predicting the class\n",
    "    res = model.predict([img])[0]\n",
    "    return np.argmax(res), max(res)\n",
    "\n",
    "class App(tk.Tk):\n",
    "    def __init__(self):\n",
    "        tk.Tk.__init__(self)\n",
    "\n",
    "        self.x = self.y = 0\n",
    "\n",
    "        # Creating elements\n",
    "        self.canvas = tk.Canvas(self, width=300, height=300, bg = \"white\", cursor=\"cross\")\n",
    "        self.label = tk.Label(self, text=\"Thinking..\", font=(\"Helvetica\", 48))\n",
    "        self.classify_btn = tk.Button(self, text = \"Recognise\", command =         self.classify_handwriting) \n",
    "        self.button_clear = tk.Button(self, text = \"Clear\", command = self.clear_all)\n",
    "\n",
    "        # Grid structure\n",
    "        self.canvas.grid(row=0, column=0, pady=2, sticky=W, )\n",
    "        self.label.grid(row=0, column=1,pady=2, padx=2)\n",
    "        self.classify_btn.grid(row=1, column=1, pady=2, padx=2)\n",
    "        self.button_clear.grid(row=1, column=0, pady=2)\n",
    "\n",
    "        #self.canvas.bind(\"<Motion>\", self.start_pos)\n",
    "        self.canvas.bind(\"<B1-Motion>\", self.draw_lines)\n",
    "\n",
    "    def clear_all(self):\n",
    "        self.canvas.delete(\"all\")\n",
    "\n",
    "    def classify_handwriting(self):\n",
    "        HWND = self.canvas.winfo_id() # get the handle of the canvas\n",
    "        rect = win32gui.GetWindowRect(HWND) # get the coordinate of the canvas\n",
    "        im = ImageGrab.grab(rect)\n",
    "\n",
    "        digit, acc = predict_digit(im)\n",
    "        self.label.configure(text= str(digit)+', '+ str(int(acc*100))+'%')\n",
    "\n",
    "    def draw_lines(self, event):\n",
    "        self.x = event.x\n",
    "        self.y = event.y\n",
    "        r=8\n",
    "        self.canvas.create_oval(self.x-r, self.y-r, self.x + r, self.y + r, fill='black')\n",
    "\n",
    "app = App()\n",
    "mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c3707e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('pydoku')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "21df5813da2c78d79906d3707346daec9326d692096f20b6334f30695c4e5055"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
